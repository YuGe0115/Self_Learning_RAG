### LLM的局限性

LLM = 分词+运算+预测+生成文本

* 知识截止（最新的知识无法获取）
* 幻觉
* 缺乏特定知识
* 不擅长精确的计算（包括很多事情的细节）

### LLM的增强策略

* RAG：外部知识库动态为LLM补充知识
* 工具调用：调用专用工具（计算器、搜索引擎等）
* finetuning：预训练模型+高质量数据微调

### RAG的优势

成本低（一个“外挂”，不需要像finetuning一样需要太多显卡）、解决幻觉、知识更新、领域定制、提高答案的可解释性。用户输入+检索结果→LLM处理生成最终结果

### RAG而非直接把整个知识库喂给LLM？

效率考量、上下文长度限制（毕竟是注意力）、token成本问题

------

